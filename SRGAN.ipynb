{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3k560A0ftRjF",
    "outputId": "f22c9495-dec3-4659-f1ac-450954c07bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRe-LBDNMCOV"
   },
   "outputs": [],
   "source": [
    "# get_ipython().system_raw(\"/content/drive/My Drive/DIV2K_train_HR.zip\")\n",
    "!unzip \"/content/drive/My Drive/DIV2K_valid_LR_wild.zip\" -d '/content/drive/My Drive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_1jSPv5Q5AU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtWPn3OJQ5RN"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from google.colab.patches import cv2_imshow\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU, Input, Flatten, PReLU, Add, Lambda, Dense\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanAbsoluteError, MeanSquaredError\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "from tensorflow.python.keras.models import Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.data.experimental import AUTOTUNE\n",
    "from easydict import EasyDict as edict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42l6NCd5dm2B"
   },
   "outputs": [],
   "source": [
    "config = edict()\n",
    "\n",
    "config.HR_TRAIN_PATH       = '/content/drive/My Drive/DIV2K_train_HR/'\n",
    "config.HR_VALID_PATH       = '/content/drive/My Drive/DIV2K_valid_HR/'\n",
    "config.LR_TRAIN_PATH       = '/content/drive/My Drive/DIV2K_train_LR/'\n",
    "config.LR_VALID_PATH       = '/content/drive/My Drive/DIV2K_valid_LR_wild/'\n",
    "\n",
    "\n",
    "config.GEN_PRE_CHECKPOINT_DIR = '/content/drive/My Drive/SRGAN/checkpoints/pretrained_gen/'\n",
    "config.SRGAN_CHECKPOINT_DIR  = '/content/drive/My Drive/SRGAN/checkpoints/'\n",
    "config.FINAL_WEIGHTS_DIR   = '/content/drive/My Drive/SRGAN/weights/'\n",
    "\n",
    "config.LR_DOWNSCALE        = 4\n",
    "config.HR_CROP_SIZE        = 96\n",
    "config.NUM_EPOCHS          = 15\n",
    "config.NUM_RES_BLOCKS      = 16\n",
    "config.NUM_UPSAMPLE_BLOCKS = 2\n",
    "config.BATCH_SIZE          = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_dqVpu8C0iW_"
   },
   "outputs": [],
   "source": [
    "DIV2k_images_mean = np.array([0.4488, 0.4371, 0.4040]) *  255\n",
    "\n",
    "\n",
    "def normalize_to_range_01(img):\n",
    "  return img / 255.0\n",
    "\n",
    "def normalize_to_range_n11(img):\n",
    "  return img / 127.5 - 1\n",
    "\n",
    "def denormalize_n11(img):\n",
    "  return (img + 1) * 127.5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuNsllNWAUx1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxoCEQf5AQ1r"
   },
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "########################## DATA LOADER AND PREPROCESSOR ######################################\n",
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VmAbwXHzAQ8Y"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "class DatasetLoader_Preprocessing:\n",
    "\n",
    "  def __init__(self, hr_train, hr_valid, lr_train, lr_valid, scale = 4):\n",
    "    self.hr_train_path = hr_train\n",
    "    self.lr_train_path = lr_train\n",
    "    self.hr_valid_path = hr_valid\n",
    "    self.lr_valid_path = lr_valid\n",
    "    self.scale = scale\n",
    "    self.get_lr_hr_names(self.hr_train_path, self.lr_train_path, 'train')\n",
    "    self.get_lr_hr_names(self.hr_valid_path, self.lr_valid_path, 'valid')\n",
    "\n",
    "\n",
    "\n",
    "  def get_only_image_nums(self, images_path):\n",
    "    image_ids = os.listdir(images_path)\n",
    "    image_ids = [image_id for image_id in image_ids if '.png' in image_id]\n",
    "    only_image_nums = []\n",
    "\n",
    "    for image_id in image_ids:\n",
    "      \n",
    "      ext_start_index = image_id.rindex('.')\n",
    "      img_str = image_id[0 : ext_start_index]\n",
    "      only_image_nums.append(img_str)\n",
    "\n",
    "    return only_image_nums\n",
    "\n",
    "\n",
    "\n",
    "  def get_full_images_paths(self, images_path, image_ids):\n",
    "    total_ids = len(image_ids)\n",
    "    for index in range(total_ids):\n",
    "      image_ids[index] = images_path + image_ids[index]\n",
    "    \n",
    "    return image_ids\n",
    "\n",
    "\n",
    "\n",
    "  def get_lr_image_names(self, hr_images_path, scale = 4):\n",
    "    lr_images_names = []\n",
    "\n",
    "    hr_images_ids = self.get_only_image_nums(hr_images_path)\n",
    "    for image_id in hr_images_ids:\n",
    "      lr_image_num = image_id + 'x' + str(scale) + 'w.png'\n",
    "      lr_images_names.append(lr_image_num)\n",
    "    \n",
    "    return lr_images_names\n",
    "\n",
    "\n",
    "  def get_lr_hr_names(self, hr_images_path, lr_images_path, dataset_type):\n",
    "    lr_images_names = self.get_lr_image_names(hr_images_path, self.scale)\n",
    "    \n",
    "    hr_images_full_ids = glob.glob(hr_images_path + '*')\n",
    "    lr_images_full_ids = self.get_full_images_paths(lr_images_path, lr_images_names)\n",
    "\n",
    "    if dataset_type == 'train':\n",
    "      self.train_hr_names = hr_images_full_ids\n",
    "      self.train_lr_names = lr_images_full_ids\n",
    "    \n",
    "    if dataset_type == 'valid':\n",
    "      self.valid_hr_names = hr_images_full_ids\n",
    "      self.valid_lr_names = lr_images_full_ids\n",
    "\n",
    "  \n",
    "\n",
    "  def random_crop(self, hr, lr):\n",
    "    lr_downscale = config.LR_DOWNSCALE\n",
    "    hr_crop_size = config.HR_CROP_SIZE\n",
    "    lr_crop_size = tf.cast((hr_crop_size / lr_downscale), tf.int32)\n",
    "\n",
    "    # hr_image_shape = tf.shape(hr)[0 : 2]\n",
    "    lr_image_shape = tf.shape(lr)[:2] # 0 - height, 1 - width\n",
    "\n",
    "    # rng = tf.random.Generator.from_non_deterministic_state() # random number generator\n",
    "    lr_w_start = tf.random.uniform((), minval = 0, maxval = lr_image_shape[1] - lr_crop_size + 1, dtype = tf.dtypes.int32)\n",
    "    lr_h_start = tf.random.uniform((), minval = 0, maxval = lr_image_shape[0] - lr_crop_size + 1, dtype = tf.dtypes.int32)\n",
    "\n",
    "    hr_w_start = lr_w_start * lr_downscale\n",
    "    hr_h_start = lr_h_start * lr_downscale\n",
    "\n",
    "    lr_crop = lr[lr_h_start : (lr_h_start + lr_crop_size), lr_w_start : (lr_w_start + lr_crop_size)]\n",
    "    hr_crop = hr[hr_h_start : (hr_h_start + hr_crop_size), hr_w_start : (hr_w_start + hr_crop_size)]\n",
    "\n",
    "    return lr_crop, hr_crop\n",
    "\n",
    "\n",
    "\n",
    "  def random_flip(self,hr, lr):\n",
    "    # rng = tf.random.Generator.from_non_deterministic_state() # random number generator\n",
    "    num = tf.random.uniform((), minval = 0, maxval = 2, dtype = tf.dtypes.int32)\n",
    "\n",
    "    return tf.cond(num == 0, \n",
    "                   lambda : (tf.image.flip_left_right(lr),\n",
    "                             tf.image.flip_left_right(hr)),\n",
    "                   lambda : (lr, hr))\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "  def get_dataset(self, image_ids):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image_ids)\n",
    "    dataset = dataset.map(lambda image_id : tf.io.read_file(image_id))\n",
    "    dataset = dataset.map(lambda png_image : tf.io.decode_png(png_image, channels = 3), num_parallel_calls = AUTOTUNE)\n",
    "    return dataset\n",
    "  \n",
    "\n",
    "\n",
    "  def get_final_dataset(self, batch_size = 16, dataset_type = 'train'):\n",
    "    if dataset_type == 'train':\n",
    "      lr_ds = self.get_dataset(self.train_lr_names)\n",
    "      hr_ds = self.get_dataset(self.train_hr_names)\n",
    "      \n",
    "    if dataset_type == 'valid':\n",
    "      hr_ds = self.get_dataset(self.valid_hr_names)\n",
    "      lr_ds = self.get_dataset(self.valid_lr_names)\n",
    "    \n",
    "    dataset = tf.data.Dataset.zip((hr_ds, lr_ds))\n",
    "    dataset = dataset.map(self.random_crop, num_parallel_calls = AUTOTUNE)\n",
    "    dataset = dataset.map(self.random_flip, num_parallel_calls = AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size = 64)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder = True)\n",
    "    # dataset = dataset.repeat()\n",
    "    dataset = dataset.prefetch(buffer_size = AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0bqBSDkdAV8A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DK4jSFaknHdr"
   },
   "outputs": [],
   "source": [
    "###################### GENERATOR ##############################\n",
    "############################################################\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxRM4ptdQ5cK"
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "  def __init__(self):\n",
    "\n",
    "    self.num_res_blocks = config.NUM_RES_BLOCKS\n",
    "    self.num_upsample_blocks = config.NUM_UPSAMPLE_BLOCKS\n",
    "  \n",
    "\n",
    "  def pixel_shuffle(self, scale):\n",
    "    return lambda data : tf.nn.depth_to_space(data, scale)\n",
    "\n",
    "\n",
    "  def conv_and_upsample(self, data, scale):\n",
    "    data = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'SAME')(data)\n",
    "    data = Lambda(self.pixel_shuffle(2))(data) # Lambda is used to convert that specific operation to a keras layer\n",
    "    data = PReLU(shared_axes = [1, 2])(data)\n",
    "    return data\n",
    "\n",
    "  def resnet_block(self, data):\n",
    "    temp_data = data\n",
    "    res_data = Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'SAME')(data)\n",
    "    res_data = BatchNormalization()(res_data)\n",
    "    res_data = PReLU(shared_axes = [1, 2])(res_data)\n",
    "    res_data = Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'SAME')(res_data)\n",
    "    res_data = BatchNormalization()(res_data)\n",
    "    res_data = Add()([temp_data, res_data])\n",
    "    return res_data\n",
    "\n",
    "  def gen_network(self):\n",
    "    in_data = Input(shape=(None, None, 3))\n",
    "    data = Lambda(normalize_to_range_01)(in_data)\n",
    "    data = Conv2D(filters = 64, kernel_size = 9, strides = (1, 1), padding = 'SAME')(data)\n",
    "    data = BatchNormalization()(data)\n",
    "    data = LeakyReLU()(data)\n",
    "    data_copy = data\n",
    "\n",
    "    for _ in range(self.num_res_blocks):\n",
    "      data = self.resnet_block(data)\n",
    "    \n",
    "    data = Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'SAME')(data)\n",
    "    data = BatchNormalization()(data)\n",
    "    data = Add()([data, data_copy])\n",
    "\n",
    "\n",
    "    for _ in range(self.num_upsample_blocks):\n",
    "      data = self.conv_and_upsample(data, 2)\n",
    "    \n",
    "    data = Conv2D(filters = 3, kernel_size = 9, strides = (1, 1), padding = 'SAME')(data)\n",
    "    data = Lambda(denormalize_n11)(data)\n",
    "    self.gen_model = tf.keras.Model(in_data, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OvHNc2AlAYrD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4YVpPdUnPAo"
   },
   "outputs": [],
   "source": [
    "##########################  DISCRIMINATOR ##################################################\n",
    "##############################################################################################\n",
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAOjHf7GuaDe"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Discriminator:\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  \n",
    "  def disc_block(self, data, n_filters, stride):\n",
    "    data = Conv2D(filters = n_filters, kernel_size = 3, strides = (stride, stride), padding = 'SAME')(data)\n",
    "    data = BatchNormalization()(data)\n",
    "    data = LeakyReLU()(data)\n",
    "    return data\n",
    "\n",
    "  def disc_network(self):\n",
    "    in_data = Input(shape=(96, 96, 3))\n",
    "    data = Lambda(normalize_to_range_n11)(in_data)\n",
    "    data = Conv2D(filters = 64, kernel_size = 3, strides = (1, 1), padding = 'SAME')(in_data)\n",
    "    data = LeakyReLU()(data)\n",
    "\n",
    "    data = self.disc_block(data, n_filters = 64, stride = 2)\n",
    "    data = self.disc_block(data, n_filters = 128, stride = 1)\n",
    "    data = self.disc_block(data, n_filters = 128, stride = 2)\n",
    "    data = self.disc_block(data, n_filters = 256, stride = 1)\n",
    "    data = self.disc_block(data, n_filters = 256, stride = 2)\n",
    "    data = self.disc_block(data, n_filters = 512, stride = 1)\n",
    "    data = self.disc_block(data, n_filters = 512, stride = 2)\n",
    "\n",
    "    data = Flatten()(data)\n",
    "    data = Dense(1024)(data)\n",
    "    data = LeakyReLU()(data)\n",
    "    data = Dense(1, activation = 'sigmoid')(data)\n",
    "    self.disc_model = tf.keras.Model(in_data, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "or554D6mAZxq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4B7JVYmjni8j"
   },
   "outputs": [],
   "source": [
    "#################################### TRAINING GENERATOR #####################################\n",
    "##############################################################################################\n",
    "##############################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "duzhuZjTnhG2"
   },
   "outputs": [],
   "source": [
    "class Generator_Training:\n",
    "  def __init__(self):\n",
    "\n",
    "    generator = Generator()\n",
    "    generator.gen_network()\n",
    "    self.learning_rate = 0.0001\n",
    "    self.mse_loss = MeanSquaredError()\n",
    "    self.generator_optimizer = Adam(learning_rate = self.learning_rate)\n",
    "    self.generator_model = generator.gen_model\n",
    "    self.checkpoint_dir = config.GEN_PRE_CHECKPOINT_DIR\n",
    "    self.checkpoint = tf.train.Checkpoint(curr_epoch = tf.Variable(0),\n",
    "                                          psnr_value = tf.Variable(-1.0),\n",
    "                                          optimizer = self.generator_optimizer,\n",
    "                                          model = self.generator_model)\n",
    "    self.checkpoint_manager = tf.train.CheckpointManager(self.checkpoint,\n",
    "                                                         directory = self.checkpoint_dir,\n",
    "                                                         max_to_keep = 5)\n",
    "\n",
    "    self.create_dirs()\n",
    "\n",
    "  def create_dirs(self):\n",
    "    if not os.path.exists(self.checkpoint_dir):\n",
    "      os.makedirs(self.checkpoint_dir)\n",
    "    \n",
    "    if not os.path.exists(config.FINAL_WEIGHTS_DIR):\n",
    "      os.makedirs(config.FINAL_WEIGHTS_DIR)\n",
    "\n",
    "    \n",
    "\n",
    "  def restore_recent_checkpoint(self):\n",
    "    # h5_weights = glob.glob(config.FINAL_WEIGHTS_DIR)\n",
    "\n",
    "    # if len(h5_weights) != 0:\n",
    "    #   self.checkpoint.model.load_weights(h5_weights[0])\n",
    "    #   print('model loaded from weights')\n",
    "    # else:\n",
    "    if self.checkpoint_manager.latest_checkpoint:\n",
    "      self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n",
    "      print('restored checkpoint successfully at epoch ' + str(self.checkpoint.curr_epoch.numpy()))\n",
    "    else:\n",
    "      print('No checkpoint restoration')\n",
    "\n",
    "\n",
    "  def train_step(self, lr, hr):\n",
    "    with tf.GradientTape(persistent = True) as grad_tape:\n",
    "      lr = tf.cast(lr, tf.float32)\n",
    "      hr = tf.cast(hr, tf.float32)\n",
    "\n",
    "      fake_hr_image = self.checkpoint.model(lr, training = True)\n",
    "      loss = self.mse_loss(hr, fake_hr_image)\n",
    "\n",
    "    gradients = grad_tape.gradient(loss, self.checkpoint.model.trainable_variables)\n",
    "    self.checkpoint.optimizer.apply_gradients(zip(gradients, self.checkpoint.model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "  def get_fake_hr_images(self, lr):\n",
    "    fake_hr_image = self.checkpoint.model(lr, training = False)\n",
    "    fake_hr_image = tf.clip_by_value(fake_hr_image, 0, 255)\n",
    "    fake_hr_image = tf.round(fake_hr_image)\n",
    "    fake_hr_image = tf.cast(fake_hr_image, tf.uint8)\n",
    "    \n",
    "\n",
    "    return fake_hr_image\n",
    "\n",
    "\n",
    "  def evaluate(self, valid_data):\n",
    "    psnr_values = []\n",
    "    count = 0\n",
    "    for hr, lr in valid_data:\n",
    "      lr = tf.cast(lr, tf.float32)\n",
    "      fake_hr_image = self.get_fake_hr_images(lr)\n",
    "      # print('in evaluation fake hr and real hr ' + str(np.shape(fake_hr_image.numpy())) + ' ' + str(np.shape(hr.numpy())) + ' ' + str(np.shape(lr.numpy())))\n",
    "      psnr = tf.image.psnr(fake_hr_image, hr, max_val=255)\n",
    "      avg_psnr = np.mean(psnr.numpy())\n",
    "      # print(str(count) + ' psnr values ' + str(psnr.numpy()))\n",
    "      # print('  ' + str(count) + ' ' + str(avg_psnr))\n",
    "      \n",
    "      psnr_values.append(avg_psnr)\n",
    "      count = count + 1\n",
    "    return tf.reduce_mean(psnr_values)\n",
    "\n",
    "\n",
    "  def display_images(self, lr, hr):\n",
    "    lr = lr.numpy()\n",
    "    hr = hr.numpy()\n",
    "    for ind in range(config.BATCH_SIZE):\n",
    "      cv2_imshow(lr[ind])\n",
    "      cv2_imshow(hr[ind])\n",
    "      print(' ')\n",
    "\n",
    "  def train_generator(self, train_data, valid_data, evaluate_step = 2, total_epochs = 10):\n",
    "    self.restore_recent_checkpoint()\n",
    "    epochs_completed = self.checkpoint.curr_epoch.numpy()\n",
    "    epochs_remaining = total_epochs - epochs_completed\n",
    "    num_of_batches = 5\n",
    "\n",
    "    psnr_value_log = tf.keras.metrics.Mean('psnr_value', dtype = tf.float32)\n",
    "    \n",
    "\n",
    "    for epoch in range(epochs_remaining):\n",
    "\n",
    "      batch_count = 0\n",
    "      act_epoch = self.checkpoint.curr_epoch.numpy()\n",
    "      print('generator training at epoch ' + str(act_epoch))\n",
    "\n",
    "      ## looping through all the batches of data \n",
    "      for hr, lr in train_data:\n",
    "        \n",
    "        loss = self.train_step(lr, hr)\n",
    "        print(' batch ' + str(batch_count) + ' training finished' + ' ' + str(np.shape(lr.numpy())) + ' ' + str(np.shape(hr.numpy())))\n",
    "        batch_count = batch_count + 1\n",
    "\n",
    "      if epoch % 10 == 0:\n",
    "        print(' ')\n",
    "        print('generator training at epoch ' + str(epoch) + ' and loss is ' + str(loss))\n",
    "\n",
    "      if epoch % evaluate_step == 0:\n",
    "        psnr_value = self.evaluate(valid_data)\n",
    "        psnr_value_log.update_state(psnr_value)\n",
    "        if self.checkpoint.psnr_value < psnr_value:\n",
    "          print('In evaluation previous psnr value is ' + str(self.checkpoint.psnr_value.numpy()) + ' and curr value is ' + str(psnr_value.numpy()))\n",
    "          self.checkpoint.psnr_value = psnr_value\n",
    "          self.checkpoint_manager.save()\n",
    "      \n",
    "      if self.checkpoint.curr_epoch.numpy() == total_epochs - 1:\n",
    "        self.checkpoint_manager.save()\n",
    "        self.checkpoint.model.save_weights(config.FINAL_WEIGHTS_DIR + 'generator_weights.h5')\n",
    "        print('weights saved')\n",
    "\n",
    "      if act_epoch != total_epochs - 1:\n",
    "        self.checkpoint.curr_epoch.assign_add(1)\n",
    "\n",
    "\n",
    "      #   self.checkpoint.curr_epoch.assign_add(1)\n",
    "      #   print(' ')\n",
    "      #   print('generator training at epoch ' + str(self.checkpoint.curr_epoch.numpy()))\n",
    "      #   count = 0 \n",
    "      # for hr, lr in train_data.take(num_of_batches * epochs_remaining):\n",
    "        # epoch = self.checkpoint.curr_epoch\n",
    "        # rand_num = tf.random.uniform((), minval = 0, maxval =  2, dtype = tf.dtypes.int32)\n",
    "        # if rand_num.numpy() == 1:\n",
    "          # self.display_images(lr, hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qrKZMP-eAzkx"
   },
   "outputs": [],
   "source": [
    "data_loader = DatasetLoader_Preprocessing(config.HR_TRAIN_PATH, config.HR_VALID_PATH, config.LR_TRAIN_PATH, config.LR_VALID_PATH, 4)\n",
    "train_data_loader = data_loader.get_final_dataset(16, 'train')\n",
    "valid_data_loader = data_loader.get_final_dataset(16, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_obj = Generator_Training()\n",
    "train_gen_obj.train_generator(train_data_loader, valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0o24C3BtFx45"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4uv7gqsAACFX"
   },
   "outputs": [],
   "source": [
    "######################################## SRGAN TRAINING ######################################\n",
    "##############################################################################################\n",
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zdL_WvIrACXg"
   },
   "outputs": [],
   "source": [
    "class SRGAN_Training:\n",
    "\n",
    "  def __init__(self):\n",
    "    # self.num_res_blocks = num_res_blocks # 16\n",
    "    # self.num_upsample_blocks = num_upsample_blocks #2\n",
    "    \n",
    "    '''\n",
    "    learning rate is 0.0001 till 10^5 iterations, after that, the learning rate should be 0.00001\n",
    "    '''\n",
    "    rate_values = [0.0001, 0.00001]\n",
    "    rate_boundary = [100000]\n",
    "    self.learning_rate = PiecewiseConstantDecay(boundaries = rate_boundary, values = rate_values)\n",
    "\n",
    "    # generator = Generator()\n",
    "    # generator.gen_network()\n",
    "    discriminator = Discriminator()\n",
    "    discriminator.disc_network()\n",
    "    # self.gen_model = generator.gen_model\n",
    "    self.gen_model = train_gen_obj.generator_model\n",
    "    self.disc_model = discriminator.disc_model\n",
    "\n",
    "    vgg = VGG19(include_top = False, input_shape = (None, None, 3))\n",
    "    self.vgg_model = Model(vgg.input, vgg.layers[20].output)\n",
    "    \n",
    "    self.generator_optimizer = Adam(learning_rate = self.learning_rate)\n",
    "    self.discriminator_optimizer = Adam(learning_rate = self.learning_rate )\n",
    "\n",
    "    self.binary_cross_entropy = BinaryCrossentropy(from_logits = False)\n",
    "    self.mean_squared_error   = MeanSquaredError()\n",
    "    \n",
    "    self.srgan_checkpoint = tf.train.Checkpoint(curr_epoch = tf.Variable(0),\n",
    "                                                g_optim = self.generator_optimizer, \n",
    "                                                d_optim = self.discriminator_optimizer,\n",
    "                                                g_model = self.gen_model, \n",
    "                                                d_model = self.disc_model)\n",
    "    self.srgan_checkpoint_manager = tf.train.CheckpointManager(self.srgan_checkpoint,\n",
    "                                                               directory = config.SRGAN_CHECKPOINT_DIR,\n",
    "                                                               max_to_keep = 3)\n",
    "\n",
    "\n",
    "  def create_dirs(self):\n",
    "    if not os.path.exists(config.SRGAN_CHECKPOINT_DIR):\n",
    "      os.makedirs(config.SRGAN_CHECKPOINT_DIR)\n",
    "    \n",
    "  \n",
    "  def disc_loss(self, logits_real, logits_fake):\n",
    "    disc_real_loss = self.binary_cross_entropy(tf.ones_like(logits_real), logits_real)\n",
    "    disc_fake_loss = self.binary_cross_entropy(tf.zeros_like(logits_fake), logits_fake)\n",
    "    return disc_real_loss + disc_fake_loss\n",
    "\n",
    "\n",
    "  def vgg_loss(self, vgg_fake, vgg_real):\n",
    "    return self.mean_squared_error(vgg_fake, vgg_real)\n",
    "\n",
    "  def gen_loss(self, fake_hr_images):\n",
    "    return self.binary_cross_entropy(tf.ones_like(fake_hr_images), fake_hr_images)\n",
    "\n",
    "  def train_step(self, hr, lr):\n",
    "    with tf.GradientTape(persistent = True) as gen_tape, tf.GradientTape(persistent = True) as disc_tape:\n",
    "      fake_hr_images = self.gen_model(lr, training = True)\n",
    "      logits_fake    = self.disc_model(fake_hr_images, training = True)\n",
    "      logits_real    = self.disc_model(hr, training = True)\n",
    "      vgg_fake       = self.vgg_model(preprocess_input(fake_hr_images)) / 12.75\n",
    "      vgg_real       = self.vgg_model(preprocess_input(hr + 1)) / 12.75\n",
    "\n",
    "      perceptual_loss    = self.vgg_loss(vgg_fake, vgg_real) + (0.0001 * self.gen_loss(logits_fake))\n",
    "      discriminator_loss = self.disc_loss(logits_real, logits_fake)\n",
    "    \n",
    "    generator_gradients = gen_tape.gradient(perceptual_loss, self.gen_model.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(discriminator_loss, self.disc_model.trainable_variables)\n",
    "\n",
    "    self.srgan_checkpoint.g_optim.apply_gradients(zip(generator_gradients, self.srgan_checkpoint.g_model.trainable_variables))\n",
    "    self.srgan_checkpoint.d_optim.apply_gradients(zip(discriminator_gradients, self.srgan_checkpoint.d_model.trainable_variables))\n",
    "\n",
    "    return perceptual_loss, discriminator_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def restore_checkpoint(self, resume_training = False):\n",
    "\n",
    "    if resume_training and self.srgan_checkpoint_manager.latest_checkpoint:\n",
    "      self.srgan_checkpoint.restore(self.srgan_checkpoint_manager.latest_checkpoint)\n",
    "      print('loaded model from srgan checkpoint')\n",
    "\n",
    "    else:\n",
    "      # latest_ckpt = tf.train.latest_checkpoint(config.GEN_PRE_CHECKPOINT_DIR)\n",
    "      # self.srgan_checkpoint.g_model.load_weights(latest_ckpt)\n",
    "      self.srgan_checkpoint.g_model.load_weights(config.FINAL_WEIGHTS_DIR + 'generator_weights.h5')\n",
    "      print('loaded pretrained generator model')      \n",
    "\n",
    "\n",
    "\n",
    "  def train(self, train_data, resume_training = True):\n",
    "    '''\n",
    "    Write function to read data batch and then perform the training'''\n",
    "    print('started SRGAN training')\n",
    "    self.create_dirs()\n",
    "    self.restore_checkpoint(resume_training)\n",
    "    if not resume_training:\n",
    "      epochs_completed = 0\n",
    "    else:\n",
    "      epochs_completed = self.srgan_checkpoint.curr_epoch\n",
    "    \n",
    "    epochs_remaining = config.NUM_EPOCHS - epochs_completed\n",
    "\n",
    "    perc_loss_log = tf.keras.metrics.Mean('perc_loss', dtype = tf.float32)\n",
    "    disc_loss_log = tf.keras.metrics.Mean('disc_loss', dtype = tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(epochs_remaining):\n",
    "      \n",
    "      act_epoch = self.srgan_checkpoint.curr_epoch\n",
    "\n",
    "      ## looping through batches of data\n",
    "      for hr, lr in train_data:\n",
    "        \n",
    "        perceptual_loss, discriminator_loss = self.train_step(hr, lr)\n",
    "        perc_loss_log.update_state(perceptual_loss)\n",
    "        disc_loss_log.update_state(discriminator_loss)\n",
    "      \n",
    "      if act_epoch % 10 == 0:\n",
    "        print('In epoch ' + str(act_epoch) + ' perceptual loss is ' + str(perc_loss_log.result()) + ' and discriminator loss is ' + str(disc_loss_log.result()))\n",
    "        perc_loss_log.reset_states()\n",
    "        disc_loss_log.reset_states()\n",
    "\n",
    "      self.srgan_checkpoint_manager.save()\n",
    "      \n",
    "      \n",
    "    \n",
    "      if act_epoch == config.NUM_EPOCHS - 1:\n",
    "        self.srgan_checkpoint.g_model.save_weights(config.FINAL_WEIGHTS_DIR + 'final_generator_weights.h5')\n",
    "        self.srgan_checkpoint.d_model.save_weights(config.FINAL_WEIGHTS_DIR + 'final_discriminator_weights.h5')\n",
    "\n",
    "      if act_epoch != config.NUM_EPOCHS - 1:\n",
    "        self.srgan_checkpoint.curr_epoch.assign_add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srgan_trainer = SRGAN_Training()\n",
    "srgan_trainer.train(train_data_loader, True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SRGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
