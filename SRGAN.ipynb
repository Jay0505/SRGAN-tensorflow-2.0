{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k560A0ftRjF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7336ef53-bf51-4b96-c2ec-50d9515bc795"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekCoB60Zxbha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.listdir('/content/drive/My Drive/DIV2K_train_HR/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRe-LBDNMCOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get_ipython().system_raw(\"/content/drive/My Drive/DIV2K_train_HR.zip\")\n",
        "!unzip \"/content/drive/My Drive/DIV2K_valid_LR_wild.zip\" -d '/content/drive/My Drive/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_1jSPv5Q5AU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtWPn3OJQ5RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU, PReLU, Add, Lambda, Dense\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, MeanAbsoluteError, MeanSquaredError\n",
        "from tf.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.data.experimental import AUTOTUNE\n",
        "from easydict import EasyDict as edict\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42l6NCd5dm2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = edict()\n",
        "\n",
        "config.HR_TRAIN_PATH       = '/content/drive/My Drive/DIV2K_train_HR/'\n",
        "config.HR_VALID_PATH       = '/content/drive/My Drive/DIV2K_valid_HR/'\n",
        "config.LR_TRAIN_PATH       = '/content/drive/My Drive/DIV2K_train_LR/'\n",
        "config.LR_VALID_PATH       = '/content/drive/My Drive/DIV2K_valid_LR_wild/'\n",
        "\n",
        "config.GEN_PRE_CHECKPOINT_DIR = '/content/drive/My Drive/SRGAN/checkpoints/pretrained_gen/'\n",
        "config.SRGAN_CHECKPOINT_DIR  = '/content/drive/My Drive/SRGAN/checkpoints/'\n",
        "config.FINAL_WEIGHTS_DIR   = '/content/drive/My Drive/SRGAN/weights/'\n",
        "\n",
        "config.LR_DOWNSCALE        = 4\n",
        "config.HR_CROP_SIZE        = 96\n",
        "config.NUM_EPOCHS          = 20000\n",
        "config.NUM_RES_BLOCKS      = 16\n",
        "config.NUM_UPSAMPLE_BLOCKS = 2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dqVpu8C0iW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DIV2k_images_mean = np.array([0.4488, 0.4371, 0.4040]) *  255\n",
        "\n",
        "\n",
        "def normalize_to_range_01(img):\n",
        "  return img / 255.0\n",
        "\n",
        "def normalize_to_range_n11(img):\n",
        "  return img / 127.5 - 1\n",
        "\n",
        "def denormalize_n11(img):\n",
        "  return (img + 1) * 127.5\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxRM4ptdQ5cK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator:\n",
        "  def __init__(self):\n",
        "\n",
        "    self.num_res_blocks = config.NUM_RES_BLOCKS\n",
        "    self.num_upsample_blocks = config.NUM_UPSAMPLE_BLOCKS\n",
        "  \n",
        "\n",
        "  def pixel_shuffle(self, data, scale):\n",
        "    return lambda data : tf.nn.depth_to_space(data, scale)\n",
        "\n",
        "\n",
        "  def conv_and_upsample(self, data, scale):\n",
        "    data = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'SAME')(data)\n",
        "    data = Lambda(self.pixel_shuffle())(data, 2) # Lambda is used to convert that specific operation to a keras layer\n",
        "    data = PReLU(shared_axes = [1, 2])(data)\n",
        "    return data\n",
        "\n",
        "  def resnet_block(self, data):\n",
        "    res_data = Conv2d(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'SAME')(data)\n",
        "    res_data = BatchNormalization()(res_data)\n",
        "    res_data = PReLU(shared_axes = [1, 2])(res_data)\n",
        "    res_data = Conv2d(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'SAME')(res_data)\n",
        "    res_data = BatchNormalization()(res_data)\n",
        "    res_data = Add()([data, res_data])\n",
        "    return res_data\n",
        "\n",
        "  def gen_network(self):\n",
        "    in_data = Input(shape=(None, None, 3))\n",
        "    data = Lambda(normalize_to_range_01)(in_data)\n",
        "    data = Conv2D(filters = 64, kernel_size = 9, strides = (1, 1), padding = 'SAME')(data)\n",
        "    data = BatchNormalization()(data)\n",
        "    data = LeakyReLU()(data)\n",
        "    data_copy = data\n",
        "\n",
        "    for _ in range(self.num_res_blocks):\n",
        "      data = self.resnet_block(data)\n",
        "    \n",
        "    data = Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'SAME')(data)\n",
        "    data = BatchNormalization()(data)\n",
        "    data = Add()([data, data_copy])\n",
        "\n",
        "\n",
        "    for _ in range(self.num_upsample_blocks):\n",
        "      data = self.conv_and_upsample(data, 2)\n",
        "    \n",
        "    data = Conv2D(filters = 3, kernel_size = 9, strides = (1, 1), padding = 'SAME')(data)\n",
        "    data = Lambda(denormalize_n11)(data)\n",
        "    self.gen_model = tf.keras.Model(in_data, data)\n",
        "\n",
        "\n",
        "\n",
        "##############################################################################################\n",
        "##############################################################################################\n",
        "\n",
        "class Discriminator:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  \n",
        "  def disc_block(self, data, n_filters, stride):\n",
        "    data = Conv2D(filters = n_filters, kernel_size = 3, strides = (stride, stride), padding = 'SAMEG')(data)\n",
        "    data = BatchNormalization()(data)\n",
        "    data = LeakyReLU()(data)\n",
        "    return data\n",
        "\n",
        "  def disc_network(self):\n",
        "    in_data = Input(shape=(96, 96, 3))\n",
        "    data = Lambda(normalize_to_range_n11)(in_data)\n",
        "    data = Conv2D(filters = 64, kernel_size = 3, strides = (1, 1), padding = 'SAME')(in_data)\n",
        "    data = LeakyReLU()(data)\n",
        "\n",
        "    data = self.disc_block(data, n_filters = 64, stride = 2)\n",
        "    data = self.disc_block(data, n_filters = 128, stride = 1)\n",
        "    data = self.disc_block(data, n_filters = 128, stride = 2)\n",
        "    data = self.disc_block(data, n_filters = 256, stride = 1)\n",
        "    data = self.disc_block(data, n_filters = 256, stride = 2)\n",
        "    data = self.disc_block(data, n_filters = 512, stride = 1)\n",
        "    data = self.disc_block(data, n_filters = 512, stride = 2)\n",
        "\n",
        "    data = Dense(1024)(data)\n",
        "    data = LeakyReLU()(data)\n",
        "    data = Dense(1, activation = 'sigmoid')(data)\n",
        "    self.disc_model = tf.keras.Model(in_data, data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################################################################################\n",
        "##############################################################################################\n",
        "\n",
        "\n",
        "\n",
        "class SRGAN_Training:\n",
        "\n",
        "  def __init__(self):\n",
        "    # self.num_res_blocks = num_res_blocks # 16\n",
        "    # self.num_upsample_blocks = num_upsample_blocks #2\n",
        "    \n",
        "    '''\n",
        "    learning rate is 0.0001 till 10^5 iterations, after that, the learning rate should be 0.00001\n",
        "    '''\n",
        "    rate_values = [0.0001, 0.00001]\n",
        "    rate_boundary = [100000]\n",
        "    self.learning_rate = PiecewiseConstantDecay(boundaries = rate_boundary, values = rate_values)\n",
        "\n",
        "    generator = Generator()\n",
        "    discriminator = Discriminator()\n",
        "\n",
        "    self.gen_model = generator.gen_model\n",
        "    self.disc_model = discriminator.disc_model\n",
        "\n",
        "    vgg = VGG19(include_top = False, input_shape = (None, None, 3))\n",
        "    self.vgg_model = Model(vgg.input, vgg.layers[20].output)\n",
        "    \n",
        "    self.generator_optimizer = Adam(learning_rate = self.learning_rate)\n",
        "    self.discriminator_optimizer = Adam(learning_rate = self.learning_rate )\n",
        "\n",
        "    self.binary_cross_entropy = BinaryCrossEntropy(from_logits = False)\n",
        "    self.mean_squared_error   = MeanSquaredError()\n",
        "    \n",
        "    self.srgan_checkpoint = tf.train.Checkpoint(curr_epoch = tf.Variable(0),\n",
        "                                                g_optim = self.generator_optimizer, \n",
        "                                                d_optim = self.discriminator_optimizer,\n",
        "                                                g_model = self.gen_model, \n",
        "                                                d_model = self.disc_modle)\n",
        "    self.srgan_checkpoint_manager = tf.train.CheckpointManager(self.srgan_checkpoint,\n",
        "                                                               directory = config.SRGAN_CHECKPOINT_DIR,\n",
        "                                                               max_to_keep = 3)\n",
        "\n",
        "\n",
        "    \n",
        "  \n",
        "  def disc_loss(self, logits_real, logits_fake)\n",
        "    disc_real_loss = self.binary_cross_entropy(tf.ones_like(logits_real), logits_real)\n",
        "    disc_fake_loss = self.binary_cross_entropy(tf.zeros_like(logits_fake), logits_fake)\n",
        "    return disc_real_loss + disc_fake_loss\n",
        "\n",
        "\n",
        "  def vgg_loss(self, vgg_fake, vgg_real):\n",
        "    return self.mean_squared_error(vgg_fake, vgg_real)\n",
        "\n",
        "  def gen_loss(self, fake_hr_images):\n",
        "    return self.binary_cross_entropy(tf.ones_like(fake_hr_images), fake_hr_images)\n",
        "\n",
        "  def train_step(self, lr, hr):\n",
        "    with tf.GradientTape(persistent = True) as gen_tape, with tf.GradientTape(persistent = True) as disc_tape:\n",
        "      fake_hr_images = self.gen_model(lr, training = True)\n",
        "      logits_fake    = self.disc_model(fake_hr_images, training = True)\n",
        "      logits_real    = self.disc_model(hr, training = True)\n",
        "      vgg_fake       = self.vgg_model(preprocess_input(fake_hr_images)) / 12.75\n",
        "      vgg_real       = self.vgg_model(preprocess_input(hr + 1)) / 12.75\n",
        "\n",
        "      perceptual_loss    = self.vgg_loss(vgg_fake, vgg_real) + (0.0001 * self.gen_loss(logits_fake))\n",
        "      discriminator_loss = self.disc_loss(logits_real, logits_fake)\n",
        "    \n",
        "    generator_gradients = gen_tape.gradient(perceptual_loss, self.gen_model.trainable_variables)\n",
        "    discriminator_gradients = disc_tape.gradient(discriminator_loss, self.disc_model.trainable_variables)\n",
        "\n",
        "    self.gen_checkpoint.optimizer.apply_gradients(zip(generator_gradients, self.gen_checkpoint.model.trainable_variables))\n",
        "    self.disc_checkpoint.optimizer.apply_gradients(zip(discriminator_gradients, self.disc_checkpoint.model.trainable_variables))\n",
        "\n",
        "    return perceptual_loss, discriminator_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def restore_checkpoint(self, resume_training = False):\n",
        "\n",
        "    if resuming and self.srgan_checkpoint_manager.latest_checkpoint:\n",
        "      self.srgan_checkpoint.restore(self.srgan_checkpoint_manager.latest_checkpoint)\n",
        "\n",
        "    else:\n",
        "      latest_ckpt = tf.train.latest_checkpoint(config.GEN_PRE_CHECKPOINT_DIR)\n",
        "      self.srgan_checkpoint.g_model.load_weights(latest_ckpt)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "  def train(self, train_data, resume_training = True):\n",
        "    '''\n",
        "    Write function to read data batch and then perform the training'''\n",
        "    self.restore_checkpoint(resume_training)\n",
        "    if not resume_training:\n",
        "      curr_epoch = 0\n",
        "    else:\n",
        "      curr_epoch = self.srgan_checkpoint.curr_epoch\n",
        "    \n",
        "    perc_loss_log = tf.keras.metrics.Mean('perc_loss', dtype = tf.float32)\n",
        "    disc_loss_log = tf.keras.metrics.Mean('disc_loss', dtype = tf.float32)\n",
        "\n",
        "\n",
        "    for epoch in range(config.NUM_EPOCHS - curr_epoch):\n",
        "      self.srgan_checkpoint.curr_epoch.assign_add(1)\n",
        "      for hr, lr in train_data.take(1):\n",
        "        \n",
        "        perceptual_loss, discriminator_loss = self.train_step(hr, lr)\n",
        "        perc_loss_log.update_state(perceptual_loss)\n",
        "        disc_loss_log.update_state(discriminator_loss)\n",
        "      \n",
        "      if epoch % 10 == 0:\n",
        "        print('In epoch ' + str(epoch) + ' perceptual loss is ' + str(perc_loss_log.result()) + ' and discriminator loss is ' + str(disc_loss_log.result()))\n",
        "        perc_loss_log.reset_states()\n",
        "        disc_loss_log.reset_states()\n",
        "      \n",
        "      self.srgan_checkpoint_manager.save()\n",
        "    \n",
        "    if epoch == config.NUM_EPOCHS - 1:\n",
        "      self.srgan_checkpoint.g_model.save_weights(config.FINAL_WEIGHTS_DIR + 'final_generator_weights.h5')\n",
        "      self.srgan_checkpoint.d_model.save_weights(config.FINAL_WEIGHTS_DIR + 'final_discriminator_weights.h5')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################################################################################\n",
        "##############################################################################################\n",
        "\n",
        "\n",
        "class Generator_Training:\n",
        "  def __init__(self):\n",
        "\n",
        "    generator = Generator()\n",
        "    self.learning_rate = 0.0001\n",
        "    self.mse_loss = MeanSquaredError()\n",
        "    self.generator_optimizer = Adam(learning_rate = self.learning_rate)\n",
        "    self.generator_model = generator.gen_model\n",
        "    self.checkpoint_dir = config.GEN_PRE_CHECKPOINT_DIR\n",
        "    self.checkpoint = tf.train.Checkpoint(curr_epoch = tf.Variable(0),\n",
        "                                          psnr_value = tf.Variable(-1.0),\n",
        "                                          optimizer = self.generator_optimizer,\n",
        "                                          model = self.generator_model)\n",
        "    self.checkpoint_manager = tf.train.CheckpointManager(self.checkpoint,\n",
        "                                                         directory = self.checkpoint_dir,\n",
        "                                                         max_to_keep = 5)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "  def restore_recent_checkpoint(self):\n",
        "    if self.checkpoint_manager.latest_checkpoint:\n",
        "      self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n",
        "      print('restored checkpoint successfully at epoch ' + str(self.checkpoint.curr_epoch.numpy()))\n",
        "\n",
        "\n",
        "\n",
        "  def train_step(self, lr, hr):\n",
        "    with tf.GradientTape(persistent = True) as grad_tape:\n",
        "      lr = tf.cast(lr, tf.float32)\n",
        "      hr = tf.cast(hr, tf.float32)\n",
        "\n",
        "      fake_hr_image = self.chekcpoint.model(lr, training = True)\n",
        "      loss = self.mse_loss(hr, fake_hr_image)\n",
        "\n",
        "    gradients = grad_tape.gradient(loss, self.checkpoint.model.trainable_variables)\n",
        "    self.checkpoint.optimizer.apply_gradients(zip(gradients, self.checkpoint.model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "\n",
        "  def get_fake_hr_images(self, lr):\n",
        "    fake_hr_image = self.checkpoint.model(lr, training = False)\n",
        "    fake_hr_image = tf.clip_by_value(fake_hr_image, (0, 255))\n",
        "    fake_hr_image = tf.round(fake_hr_image)\n",
        "    fake_hr_image = tf.cast(fake_hr_image, tf.uint8)\n",
        "    \n",
        "\n",
        "    return fake_hr_image\n",
        "\n",
        "\n",
        "  def evaluate(self, valid_data):\n",
        "    psnr_values = []\n",
        "    for lr, hr in valid_data:\n",
        "      lr = tf.cast(lr, tf.float32)\n",
        "      fake_hr_image = self.get_fake_hr_images(lr)\n",
        "      psnr = tf.image.psnr(fake_hr_image, hr, max_val=255)\n",
        "      psnr_values.append(psnr)\n",
        "    \n",
        "    return tf.reduce_mean(psnr_values)\n",
        "\n",
        "\n",
        "  def train_generator(self, train_data, valid_data, evaluate_step = 1000, total_epochs = 100000):\n",
        "    self.restore_recent_checkpoint()\n",
        "    for hr, lr in train_data.take(total_epochs - self.checkpoint.curr_epoch.numpy()):\n",
        "      self.checkpoint.curr_epoch.assign_add(1)\n",
        "      epoch = self.checkpoint.curr_epoch\n",
        "      loss = self.train_step(lr, hr)\n",
        "      \n",
        "      if epoch % 10 == 0:\n",
        "        print('generator training at epoch ' + str(epoch) + ' and loss is ' + str(loss))\n",
        "      if epoch % evaluate_step == 0:\n",
        "        psnr_value = self.evaluate(valid_data)\n",
        "\n",
        "        if self.checkpoint.psnr_value < psnr_value:\n",
        "          self.checkpoint.psnr_value = psnr_value\n",
        "          self.checkpoint_manager.save()\n",
        "      \n",
        "      if epoch == total_epochs - 1:\n",
        "        self.checkpoint.model.save_weights(config.FINAL_WEIGHTS_DIR + 'generator_weights.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAOjHf7GuaDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btSSW_a7uajM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############################################################################################\n",
        "########################## DATA LOADER AND PREPROCESSOR ######################################\n",
        "##############################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_5GzQsLUcfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "\n",
        "class DatasetLoader_Preprocessing:\n",
        "\n",
        "  def __init__(self, hr_train, hr_valid, lr_train, lr_valid, scale = 4):\n",
        "    self.hr_train_path = hr_train\n",
        "    self.lr_train_path = lr_train\n",
        "    self.hr_valid_path = hr_valid\n",
        "    self.lr_valid_path = lr_valid\n",
        "    self.scale = scale\n",
        "    # self.get_lr_hr_names(self.hr_train_path, self.lr_train_path, 'train')\n",
        "    self.get_lr_hr_names(self.hr_valid_path, self.lr_valid_path, 'valid')\n",
        "\n",
        "\n",
        "\n",
        "  def get_only_image_nums(self, images_path):\n",
        "    image_ids = os.listdir(images_path)\n",
        "    image_ids = [image_id for image_id in image_ids if '.png' in image_id]\n",
        "    only_image_nums = []\n",
        "\n",
        "    for image_id in image_ids:\n",
        "      \n",
        "      ext_start_index = image_id.rindex('.')\n",
        "      img_str = image_id[0 : ext_start_index]\n",
        "      only_image_nums.append(img_str)\n",
        "\n",
        "    return only_image_nums\n",
        "\n",
        "\n",
        "\n",
        "  def get_full_images_paths(self, images_path, image_ids):\n",
        "    total_ids = len(image_ids)\n",
        "    for index in range(total_ids):\n",
        "      image_ids[index] = images_path + image_ids[index]\n",
        "    \n",
        "    return image_ids\n",
        "\n",
        "\n",
        "\n",
        "  def get_lr_image_names(self, hr_images_path, scale = 4):\n",
        "    lr_images_names = []\n",
        "\n",
        "    hr_images_ids = self.get_only_image_nums(hr_images_path)\n",
        "    for image_id in hr_images_ids:\n",
        "      lr_image_num = image_id + 'x' + str(scale) + 'w.png'\n",
        "      lr_images_names.append(lr_image_num)\n",
        "    \n",
        "    return lr_images_names\n",
        "\n",
        "\n",
        "  def get_lr_hr_names(self, hr_images_path, lr_images_path, dataset_type):\n",
        "    lr_images_names = get_lr_image_names(hr_images_path, self.scale)\n",
        "    \n",
        "    hr_images_full_ids = glob.glob(hr_images_path + '*')\n",
        "    lr_images_full_ids = self.get_full_images_paths(lr_images_path, lr_images_names)\n",
        "\n",
        "    if dataset_type == 'train':\n",
        "      self.train_hr_names = hr_images_full_ids\n",
        "      self.train_lr_names = lr_images_full_ids\n",
        "    \n",
        "    if dataset_type == 'valid':\n",
        "      self.valid_hr_names = hr_images_full_ids\n",
        "      self.valid_lr_names = lr_images_full_ids\n",
        "\n",
        "  \n",
        "\n",
        "  def random_crop(self, hr, lr):\n",
        "    lr_downscale = config.LR_DOWNSCALE\n",
        "    hr_crop_size = config.HR_CROP_SIZE\n",
        "    lr_crop_size = tf.cast((hr_crop_size / lr_downscale), tf.int32)\n",
        "\n",
        "    # hr_image_shape = tf.shape(hr)[0 : 2]\n",
        "    lr_image_shape = tf.shape(lr)[:2] # 0 - height, 1 - width\n",
        "\n",
        "    # rng = tf.random.Generator.from_non_deterministic_state() # random number generator\n",
        "    lr_w_start = tf.random.uniform((), minval = 0, maxval = lr_image_shape[1] - lr_crop_size + 1, dtype = tf.dtypes.int32)\n",
        "    lr_h_start = tf.random.uniform((), minval = 0, maxval = lr_image_shape[0] - lr_crop_size + 1, dtype = tf.dtypes.int32)\n",
        "\n",
        "    hr_w_start = lr_w_start * lr_downscale\n",
        "    hr_h_start = lr_h_start * lr_downscale\n",
        "\n",
        "    lr_crop = lr[lr_h_start : (lr_h_start + lr_crop_size), lr_w_start : (lr_w_start + lr_crop_size)]\n",
        "    hr_crop = hr[hr_h_start : (hr_h_start + hr_crop_size), hr_w_start : (hr_w_start + hr_crop_size)]\n",
        "\n",
        "    return lr_crop, hr_crop\n",
        "\n",
        "\n",
        "\n",
        "  def random_flip(self,hr, lr):\n",
        "    # rng = tf.random.Generator.from_non_deterministic_state() # random number generator\n",
        "    num = tf.random.uniform((), minval = 0, maxval = 2, dtype = tf.dtypes.int32)\n",
        "\n",
        "    return tf.cond(num == 0, \n",
        "                   lambda : (tf.image.flip_left_right(lr),\n",
        "                             tf.image.flip_left_right(hr)),\n",
        "                   lambda : (lr, hr))\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  def get_dataset(self, image_ids):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(image_ids)\n",
        "    dataset = dataset.map(lambda image_id : tf.io.read_file(image_id))\n",
        "    dataset = dataset.map(lambda png_image : tf.io.decode_png(png_image, channels = 3), num_parallel_calls = AUTOTUNE)\n",
        "    return dataset\n",
        "  \n",
        "\n",
        "\n",
        "  def get_final_dataset(self, batch_size = 16, dataset_type = 'train'):\n",
        "    if dataset_type == 'train':\n",
        "      lr_ds = self.get_dataset(self.train_lr_names)\n",
        "      hr_ds = self.get_dataset(self.train_hr_names)\n",
        "    \n",
        "    if dataset_type == 'valid':\n",
        "      hr_ds = self.get_dataset(self.valid_hr_names)\n",
        "      lr_ds = self.get_dataset(self.valid_lr_names)\n",
        "\n",
        "    dataset = tf.data.Dataset.zip((hr_ds, lr_ds))\n",
        "    dataset = dataset.map(self.random_crop, num_parallel_calls = AUTOTUNE)\n",
        "    dataset = dataset.map(self.random_flip, num_parallel_calls = AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder = True)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch(buffer_size = AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "data_loader = DatasetLoader_Preprocessing(config.HR_TRAIN_PATH, config.HR_VALID_PATH, config.LR_TRAIN_PATH, config.LR_VALID_PATH, 4)\n",
        "dataset = data_loader.get_final_dataset(16, 'valid')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdpKMW7w2cmw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "455eeb43-0c04-482d-9055-bd7a968ca78a"
      },
      "source": [
        "import glob\n",
        "import cv2\n",
        "\n",
        "DIV_MEAN = np.array([0.4488, 0.4371, 0.4040]) * 255\n",
        "\n",
        "image_id = glob.glob('/content/drive/My Drive/temp_data/lr_train/*')\n",
        "img = cv2.imread(image_id[0])\n",
        "img = (img - DIV_MEAN) / 127.5\n",
        "print(np.min(img), np.max(img))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.8976 1.192\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}